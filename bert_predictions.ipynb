{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Q/A Model for document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is attention mechanism\"\n",
    "# true_answer = \"The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.\"\n",
    "\n",
    "# question = \"What is quantum entanglement\"\n",
    "# true_answer = \"Quantum Entanglement allows qubits that are separated by incredible distances to interact with each other instantaneously (not limited to the speed of light).\"\n",
    "\n",
    "question = \"What are the applications of Face Swapping\"\n",
    "true_answer = \"Face swapping has a number of compelling applications in video compositing, transfiguration in portraits, and especially in  identity  protection  as  it  can  replace  faces  in  photographs by ones from a collection of stock images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large Cased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [re.sub(r'\\n', ' ', content) for content in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:27, 96.77s/it] \n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), 50):\n",
    "        paragraph = content.split(\" \")[i:i+50]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6750</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>8.850172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>identity protection</td>\n",
       "      <td>1950</td>\n",
       "      <td>1965</td>\n",
       "      <td>1966</td>\n",
       "      <td>8.820515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17552</td>\n",
       "      <td>17560</td>\n",
       "      <td>8.465274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>applied to a [UNK] document or to a vocabulary</td>\n",
       "      <td>4000</td>\n",
       "      <td>4011</td>\n",
       "      <td>4019</td>\n",
       "      <td>8.246582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>[UNK] Creation and [UNK] A Survey</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>7.6255054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                answer  chunk  start_loc  \\\n",
       "0     to show wave nature and particle nature of light   6750       6802   \n",
       "1                                  identity protection   1950       1965   \n",
       "2  [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo [UNK]  17500      17552   \n",
       "3       applied to a [UNK] document or to a vocabulary   4000       4011   \n",
       "4                    [UNK] Creation and [UNK] A Survey      0         14   \n",
       "\n",
       "   end_loc      logit  \n",
       "0     6810   8.850172  \n",
       "1     1966   8.820515  \n",
       "2    17560   8.465274  \n",
       "3     4019   8.246582  \n",
       "4       19  7.6255054  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "                                      Fig 3: Example to show wave nature and particle nature of light\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "portraits, and especially in identity protection as it can replace faces in photographs by ones from a collection of stock images. However, it is also one of the techniques that cyber attackers employ to penetrate identiﬁcation or authentication systems to gain illegitimate access. The use of deep learning such as\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "He is cur- rently an Associate Professor with the Department of Sciences and Methods for Engineering, Univer- sity of Modena and Reggio Emilia, Modena, Italy. His work focuses on machine learning and artiﬁ- cial intelligence, with applications to several areas, including argumentation mining, legal informatics, and medicine.  Paolo Torroni\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "applied to a textual document or to a vocabulary to perform a classiﬁcation among the words.  Finally, attention can come in handy when multiple inter- acting input sequences have to be considered in combination. In tasks such as question answering, where the input consists the question and of two\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "Deep Learning for Deepfakes Creation and Detection: A Survey  Thanh Thi Nguyen, Cuong M. Nguyen, Dung Tien Nguyen, Duc Thanh Nguyen, Saeid Nahavandi, Fellow, IEEE  1  0 2 0 2   l u J   8 2     ]  V C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+50]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6750</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>8.850172</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>identity protection</td>\n",
       "      <td>1950</td>\n",
       "      <td>1965</td>\n",
       "      <td>1966</td>\n",
       "      <td>8.820515</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17552</td>\n",
       "      <td>17560</td>\n",
       "      <td>8.465274</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>applied to a [UNK] document or to a vocabulary</td>\n",
       "      <td>4000</td>\n",
       "      <td>4011</td>\n",
       "      <td>4019</td>\n",
       "      <td>8.246582</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>[UNK] Creation and [UNK] A Survey</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>7.6255054</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                answer  chunk  start_loc  \\\n",
       "0     to show wave nature and particle nature of light   6750       6802   \n",
       "1                                  identity protection   1950       1965   \n",
       "2  [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo [UNK]  17500      17552   \n",
       "3       applied to a [UNK] document or to a vocabulary   4000       4011   \n",
       "4                    [UNK] Creation and [UNK] A Survey      0         14   \n",
       "\n",
       "   end_loc      logit        f1  \n",
       "0     6810   8.850172  0.097561  \n",
       "1     1966   8.820515  0.117647  \n",
       "2    17560   8.465274  0.048780  \n",
       "3     4019   8.246582  0.000000  \n",
       "4       19  7.6255054  0.054054  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Base Cased SQuAD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-cased-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:08, 32.04s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), 50):\n",
    "        paragraph = content.split(\" \")[i:i+50]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>require design and build specific</td>\n",
       "      <td>9150</td>\n",
       "      <td>9206</td>\n",
       "      <td>9210</td>\n",
       "      <td>14.402318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>large scale visual recognition</td>\n",
       "      <td>9300</td>\n",
       "      <td>9352</td>\n",
       "      <td>9355</td>\n",
       "      <td>11.4281025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6750</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>11.141766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>metric learning by online soft mining</td>\n",
       "      <td>16300</td>\n",
       "      <td>16333</td>\n",
       "      <td>16338</td>\n",
       "      <td>9.319881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>videos from appearance and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UN...</td>\n",
       "      <td>11150</td>\n",
       "      <td>11170</td>\n",
       "      <td>11203</td>\n",
       "      <td>9.22681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                    require design and build specific   \n",
       "1                                                                       large scale visual recognition   \n",
       "2                                                     to show wave nature and particle nature of light   \n",
       "3                                                                metric learning by online soft mining   \n",
       "4  videos from appearance and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UN...   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit  \n",
       "0   9150       9206     9210   14.402318  \n",
       "1   9300       9352     9355  11.4281025  \n",
       "2   6750       6802     6810   11.141766  \n",
       "3  16300      16333    16338    9.319881  \n",
       "4  11150      11170    11203     9.22681  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "answer this question. The contradiction discovered by Bell in EPR paper, is  so  subtle  that  it  appears  only  in  a  very  peculiar  situations  that  had  not  been  investigated. And require design and build specific\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "T., Laine, S., and Lehtinen, J. (2017). Progressive growing of GANs for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196.  [75] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., ... and Berg, A. C. (2015). ImageNet large scale visual recognition challenge. International Journal of Computer\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "                                      Fig 3: Example to show wave nature and particle nature of light\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS  [129] X. Wang, Y. Hua, E. Kodirov, G. Hu, and N. M. Robertson, “Deep metric learning by online soft mining and class-aware attention,” in Proc. AAAI, 2019, pp. 5361–5368, doi: 10.1609/aaai.v33i01.33015361. [130] J. B. Lee, R. A. Rossi, S. Kim, N. K.\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "H., and Lim, S. N. (2020). Detect- ing deep-fake videos from appearance and behavior. arXiv preprint arXiv:2004.14491.  [135] Agarwal, S., Farid, H., Gu, Y., He, M., Nagano, K., and Li, H. (2019, June). Protecting world leaders against deep fakes. In Computer Vision and Pattern Recognition Workshops (pp. 38-45). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+50]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>require design and build specific</td>\n",
       "      <td>9150</td>\n",
       "      <td>9206</td>\n",
       "      <td>9210</td>\n",
       "      <td>14.402318</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>large scale visual recognition</td>\n",
       "      <td>9300</td>\n",
       "      <td>9352</td>\n",
       "      <td>9355</td>\n",
       "      <td>11.4281025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6750</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>11.141766</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>metric learning by online soft mining</td>\n",
       "      <td>16300</td>\n",
       "      <td>16333</td>\n",
       "      <td>16338</td>\n",
       "      <td>9.319881</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>videos from appearance and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UN...</td>\n",
       "      <td>11150</td>\n",
       "      <td>11170</td>\n",
       "      <td>11203</td>\n",
       "      <td>9.22681</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                    require design and build specific   \n",
       "1                                                                       large scale visual recognition   \n",
       "2                                                     to show wave nature and particle nature of light   \n",
       "3                                                                metric learning by online soft mining   \n",
       "4  videos from appearance and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UN...   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit        f1  \n",
       "0   9150       9206     9210   14.402318  0.054054  \n",
       "1   9300       9352     9355  11.4281025  0.000000  \n",
       "2   6750       6802     6810   11.141766  0.097561  \n",
       "3  16300      16333    16338    9.319881  0.052632  \n",
       "4  11150      11170    11203     9.22681  0.090909  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large uncased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:10, 92.57s/it] \n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), 50):\n",
    "        paragraph = content.split(\" \")[i:i+50]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit  \n",
       "0   2300       2310     2315   11.70063  \n",
       "1  17500      17551    17558   11.60136  \n",
       "2   9500       9529     9533  10.294424  \n",
       "3   6050       6070     6074  10.155699  \n",
       "4   7600       7625     7659  10.107832  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "fake image detection and face video detection.  requires a large database of real and fake videos to train clas- siﬁcation models. The number of fake videos is increasingly available, but it is still limited in terms of setting a benchmark for validating various detection methods. To address this issue,\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "He is cur- rently an Associate Professor with the Department of Sciences and Methods for Engineering, Univer- sity of Modena and Reggio Emilia, Modena, Italy. His work focuses on machine learning and artiﬁ- cial intelligence, with applications to several areas, including argumentation mining, legal informatics, and medicine.  Paolo Torroni\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "(MIPR) (pp. 384-389). IEEE.  [82] Hsu, C. C., Lee, C. Y., and Zhuang, Y. X. (2018, December). Learning to detect fake face images in the wild. In 2018 International Symposium on Computer, Consumer and Control (IS3C) (pp. 388-391). IEEE. [83] Afchar, D., Nozick, V., Yamagishi, J., and Echizen, I.\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "instance, keywords can be used as a query, such as abusive speech recognition and sentiment analysis.  A different approach amounts to combining rather than comparing K and q, using them together to compute a joint representation, which is then multiplied by an importance vector3 wi mp, which has to\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "extended to accommodate multiple, possibly heterogeneous, inputs or outputs.  1) Multiple Outputs: Some applications suggest that the data could, and should, be interpreted in multiple ways. This can be the case when there is ambiguity in the data, stemming, for example, from words having multiple meanings or when addressing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+50]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit        f1  \n",
       "0   2300       2310     2315   11.70063  0.157895  \n",
       "1  17500      17551    17558   11.60136  0.050000  \n",
       "2   9500       9529     9533  10.294424  0.108108  \n",
       "3   6050       6070     6074  10.155699  0.054054  \n",
       "4   7600       7625     7659  10.107832  0.125000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
