{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Q/A Model for document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:37, 72.42s/it]\n"
     ]
    }
   ],
   "source": [
    "question = \"What is attention mechanism\"\n",
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), 50):\n",
    "        paragraph = content.split(\" \")[i:i+50]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>The tip</td>\n",
       "      <td>950</td>\n",
       "      <td>1001</td>\n",
       "      <td>1002</td>\n",
       "      <td>10.519569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/nlp.pdf</td>\n",
       "      <td>compatibility function using a [UNK] network [UNK] single hidden [UNK]</td>\n",
       "      <td>1300</td>\n",
       "      <td>1328</td>\n",
       "      <td>1337</td>\n",
       "      <td>10.337739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/nlp.pdf</td>\n",
       "      <td>allows the model to jointly attend to information from different [UNK] at different [UNK]</td>\n",
       "      <td>1500</td>\n",
       "      <td>1541</td>\n",
       "      <td>1554</td>\n",
       "      <td>10.0983715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/nlp.pdf</td>\n",
       "      <td>Two attention</td>\n",
       "      <td>4950</td>\n",
       "      <td>4998</td>\n",
       "      <td>4999</td>\n",
       "      <td>9.729937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/nlp.pdf</td>\n",
       "      <td>the attention function on a set of [UNK] [UNK] packed [UNK] a matrix</td>\n",
       "      <td>1250</td>\n",
       "      <td>1258</td>\n",
       "      <td>1270</td>\n",
       "      <td>8.547232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      path  \\\n",
       "0  /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                /home/jupyter/nlp_document_finder/Google/research/nlp.pdf   \n",
       "2                /home/jupyter/nlp_document_finder/Google/research/nlp.pdf   \n",
       "3                /home/jupyter/nlp_document_finder/Google/research/nlp.pdf   \n",
       "4                /home/jupyter/nlp_document_finder/Google/research/nlp.pdf   \n",
       "\n",
       "                                                                                      answer  \\\n",
       "0                                                                                    The tip   \n",
       "1                     compatibility function using a [UNK] network [UNK] single hidden [UNK]   \n",
       "2  allows the model to jointly attend to information from different [UNK] at different [UNK]   \n",
       "3                                                                              Two attention   \n",
       "4                       the attention function on a set of [UNK] [UNK] packed [UNK] a matrix   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit  \n",
       "0    950       1001     1002   10.519569  \n",
       "1   1300       1328     1337   10.337739  \n",
       "2   1500       1541     1554  10.0983715  \n",
       "3   4950       4998     4999    9.729937  \n",
       "4   1250       1258     1270    8.547232  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'large, assume that the components of q and k are independent random\\ni=1 qiki, has mean 0 and variance dk.\\n\\nvariables with mean 0 and variance 1. Then their dot product, q · k = (cid:80)dk\\n\\n4\\n\\n\\x0cMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(contents[0].split(\" \")[1500: 1500+50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
