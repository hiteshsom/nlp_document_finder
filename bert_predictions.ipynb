{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Q/A Model for document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many people work at Amazon\"\n",
    "true_answer = \"Amazon directly employs 840,000workers worldwide\"\n",
    "\n",
    "# question = \"How many position were opened in March\"\n",
    "# true_answer = \"100000\"\n",
    "\n",
    "# question = \"How many new people hired by amazon\"\n",
    "# true_answer = \"100000\"\n",
    "\n",
    "# question = \"What are dominant sequence transduction models based on\"\n",
    "# true_answer = \" complex recurrent or convolutional neural networks that include an encoder and a decoder\"\n",
    "\n",
    "# question = \"What is attention mechanism\"\n",
    "# true_answer = \"The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.\"\n",
    "\n",
    "# question = \"What is quantum entanglement\"\n",
    "# true_answer = \"Quantum Entanglement allows qubits that are separated by incredible distances to interact with each other instantaneously (not limited to the speed of light).\"\n",
    "\n",
    "# question = \"What are the applications of Face Swapping\"\n",
    "# true_answer = \"Face swapping has a number of compelling applications in video compositing, transfiguration in portraits, and especially in  identity  protection  as  it  can  replace  faces  in  photographs by ones from a collection of stock images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hiteshsom\\\\Documents\\\\nlp_document_finder\\\\notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "DIRECTORY = 'C:\\\\Users\\\\hiteshsom\\\\Documents\\\\nlp_document_finder'\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large Cased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [re.sub(r'\\n', ' ', content) for content in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = contents[0].split('  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First try with one paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Beyond COVID\", \"Leveraging scale for good\"]\n",
    "paragraphs = [\"Although these are incredibly difficult times, they are an important reminder that what we do as a company canmake a big difference in people’s lives. Customers count on us to be there, and we are fortunate to be able tohelp. With our scale and ability to innovate quickly, Amazon can make a positive impact and be an organizingforce for progress.Last year, we co-founded The Climate Pledge with Christiana Figueres, the UN’s former climate change chiefand founder of Global Optimism, and became the first signatory to the pledge. The pledge commits Amazon tomeet the goals of the Paris Agreement 10 years early—and be net zero carbon by 2040. Amazon faces significantchallenges in achieving this goal because we don’t just move information around—we have extensive physicalinfrastructure and deliver more than 10 billion items worldwide a year. And we believe if Amazon can get to netzero carbon ten years early, any company can—and we want to work together with all companies to make it areality.To that end, we are recruiting other companies to sign The Climate Pledge. Signatories agree to measure andreport greenhouse gas emissions regularly, implement decarbonization strategies in line with the ParisAgreement, and achieve net zero annual carbon emissions by 2040. (We’ll be announcing new signatories soon.)We plan to meet the pledge, in part, by purchasing 100,000 electric delivery vans from Rivian—a Michigan-based producer of electric vehicles. Amazon aims to have 10,000 of Rivian’s new electric vans on the road asearly as 2022, and all 100,000 vehicles on the road by 2030. That’s good for the environment, but the promise iseven greater. This type of investment sends a signal to the marketplace to start inventing and developing newtechnologies that large, global companies need to transition to a low-carbon economy. We’ve also committed to reaching 80% renewable energy by 2024 and 100% renewable energy by 2030. (Theteam is actually pushing to get to 100% by 2025 and has a challenging but credible plan to pull that off.)Globally, Amazon has 86 solar and wind projects that have the capacity to generate over 2,300 MW and delivermore than 6.3 million MWh of energy annually—enough to power more than 580,000 U.S. homes.We’ve made tremendous progress cutting packaging waste. More than a decade ago, we created the Frustration-Free Packaging program to encourage manufacturers to package their products in easy-to-open, 100% recyclablepackaging that is ready to ship to customers without the need for an additional shipping box. Since 2008, thisprogram has saved more than 810,000 tons of packaging material and eliminated the use of 1.4 billion shippingboxes.We are making these significant investments to drive our carbon footprint to zero despite the fact that shoppingonline is already inherently more carbon efficient than going to the store. Amazon’s sustainability scientists havespent more than three years developing the models, tools, and metrics to measure our carbon footprint. Theirdetailed analysis has found that shopping online consistently generates less carbon than driving to a store, since asingle delivery van trip can take approximately 100 roundtrip car journeys off the road on average. Our scientistsdeveloped a model to compare the carbon intensity of ordering Whole Foods Market groceries online versusdriving to your nearest Whole Foods Market store. The study found that, averaged across all basket sizes, onlinegrocery deliveries generate 43% lower carbon emissions per item compared to shopping in stores. Smaller basketsizes generate even greater carbon savings.AWS is also inherently more efficient than the traditional in-house data center. That’s primarily due to twothings—higher utilization, and the fact that our servers and facilities are more efficient than what mostcompanies can achieve running their own data centers. Typical single-company data centers operate at roughly18% server utilization. They need that excess capacity to handle large usage spikes. AWS benefits from multi-tenant usage patterns and operates at far higher server utilization rates. In addition, AWS has been successful inincreasing the energy efficiency of its facilities and equipment, for instance by using more efficient evaporativecooling in certain data centers instead of traditional air conditioning. A study by 451 Research found that AWS’sinfrastructure is 3.6 times more energy efficient than the median U.S. enterprise data center surveyed. Along withour use of renewable energy, these factors enable AWS to do the same tasks as traditional data centers with an88% lower carbon footprint. And don’t think we’re not going to get those last 12 points—we’ll make AWS 100%carbon free through more investments in renewable energy projects.\", \"Over the last decade, no company has created more jobs than Amazon. Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia. In total, Amazondirectly and indirectly supports 2 million jobs in the U.S., including 680,000-plus jobs created by Amazon’sinvestments in areas like construction, logistics, and professional services, plus another 830,000 jobs created bysmall and medium-sized businesses selling on Amazon. Globally, we support nearly 4 million jobs. We areespecially proud of the fact that many of these are entry-level jobs that give people their first opportunity toparticipate in the workforce.And Amazon’s jobs come with an industry-leading $15 minimum wage and comprehensive benefits. More than40 million Americans—many making the federal minimum wage of $7.25 an hour—earn less than the lowest-paid Amazon associate. When we raised our starting minimum wage to $15 an hour in 2018, it had an immediateand meaningful impact on the hundreds of thousands of people working in our fulfillment centers. We want otherbig employers to join us by raising their own minimum pay rates, and we continue to lobby for a $15 federalminimum wage.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the last decade, no company has created more jobs than Amazon. Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia. In total, Amazondirectly and indirectly supports 2 million jobs in the U.S., including 680,000-plus jobs created by Amazon’sinvestments in areas like construction, logistics, and professional services, plus another 830,000 jobs created bysmall and medium-sized businesses selling on Amazon. Globally, we support nearly 4 million jobs. We areespecially proud of the fact that many of these are entry-level jobs that give people their first opportunity toparticipate in the workforce.And Amazon’s jobs come with an industry-leading $15 minimum wage and comprehensive benefits. More than40 million Americans—many making the federal minimum wage of $7.25 an hour—earn less than the lowest-paid Amazon associate. When we raised our starting minimum wage to $15 an hour in 2018, it had an immediateand meaningful impact on the hundreds of thousands of people working in our fulfillment centers. We want otherbig employers to join us by raising their own minimum pay rates, and we continue to lobby for a $15 federalminimum wage.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraph = content.split(\".\")[i:i+CHUNK_SIZE]\n",
    "i=0\n",
    "answers = []\n",
    "encoding = tokenizer.encode_plus(text=question, text_pair=paragraphs[1])\n",
    "inputs = encoding['input_ids']  #Token embeddings\n",
    "sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "start_index = torch.argmax(start_scores)\n",
    "end_index = torch.argmax(end_scores)\n",
    "answer = ' '.join(tokens[start_index:end_index+1])\n",
    "if start_index.numpy() < end_index.numpy():\n",
    "    answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'paragraph_num', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>paragraph_num</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>84 ##0 , 000 ##work ##ers worldwide</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>10.732975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                path  \\\n",
       "0  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "\n",
       "                                answer  paragraph_num  start_loc  end_loc  \\\n",
       "0  84 ##0 , 000 ##work ##ers worldwide              0         25       31   \n",
       "\n",
       "       logit  \n",
       "0  10.732975  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = []\n",
    "# for path, content in tqdm(zip(paths, contents)):\n",
    "#     for i in range(0, len(content.split(\" \")), CHUNK_SIZE):\n",
    "#         paragraph = content.split(\" \")[i:i+CHUNK_SIZE]\n",
    "# #         print(paragraph)\n",
    "#         encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "#         inputs = encoding['input_ids']  #Token embeddings\n",
    "#         sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "#         tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "#         start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "#         start_index = torch.argmax(start_scores)\n",
    "#         end_index = torch.argmax(end_scores)\n",
    "#         answer = ' '.join(tokens[start_index:end_index+1])\n",
    "#         if start_index.numpy() < end_index.numpy():\n",
    "#             answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [00:15<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "i=0\n",
    "for content in tqdm(contents):\n",
    "    paragraph = content\n",
    "    if len(paragraph)>50: # Assumption: A paragraph should be atleast 50 charachters long\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([paths[0], answer, i, start_index.numpy(), end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])  \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'paragraph_num', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>paragraph_num</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>84 ##0 , 000</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>11.047459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>hundreds of thousands</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>8.451773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>Amazon ##ians are working around the clock</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5.787483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>A team of Amazon ##ians — from research scientists and program managers to pro ##curement specia...</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>41</td>\n",
       "      <td>5.404784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>100 , 000</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5.1770725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>unprecedented numbers of employees online and productive from home</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>4.510557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>10 billion</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>3.951603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>associates from those closed stores the opportunity to continue working in other parts of Amazon .</td>\n",
       "      <td>9</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>1.1158783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>6 , 000</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0136613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>Amazon has 86</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>0.076636076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                path  \\\n",
       "0  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "1  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "2  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "3  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "4  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "5  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "6  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "7  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "8  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "9  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                                         84 ##0 , 000   \n",
       "1                                                                                hundreds of thousands   \n",
       "2                                                           Amazon ##ians are working around the clock   \n",
       "3  A team of Amazon ##ians — from research scientists and program managers to pro ##curement specia...   \n",
       "4                                                                                            100 , 000   \n",
       "5                                   unprecedented numbers of employees online and productive from home   \n",
       "6                                                                                           10 billion   \n",
       "7   associates from those closed stores the opportunity to continue working in other parts of Amazon .   \n",
       "8                                                                                              6 , 000   \n",
       "9                                                                                        Amazon has 86   \n",
       "\n",
       "   paragraph_num start_loc end_loc        logit  \n",
       "0             33        25      28    11.047459  \n",
       "1             34        81      83     8.451773  \n",
       "2              8         8      14     5.787483  \n",
       "3             13        22      41     5.404784  \n",
       "4             15        13      15    5.1770725  \n",
       "5             17        55      63     4.510557  \n",
       "6             25       105     106     3.951603  \n",
       "7              9        84      99    1.1158783  \n",
       "8             16        56      58    1.0136613  \n",
       "9             28        61      63  0.076636076  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:15, 15.06s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\".\")), 1):\n",
    "        paragraph = content.split(\".\")[i:i+CHUNK_SIZE]\n",
    "#         print(paragraph)\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>S [UNK] [UNK]</td>\n",
       "      <td>119</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>5.1334352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>4.455745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>121</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>4.455745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>4.455745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>4.455745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                path  \\\n",
       "0  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "1  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "2  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "3  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "4  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "\n",
       "          answer  chunk  start_loc  end_loc      logit  \n",
       "0  S [UNK] [UNK]    119        127      129  5.1334352  \n",
       "1        [UNK] S     92        100      101   4.455745  \n",
       "2        [UNK] S    121        129      130   4.455745  \n",
       "3        [UNK] S     27         35       36   4.455745  \n",
       "4        [UNK] S    112        120      121   4.455745  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf\u001b[0m\n",
      "S , 115,000 in Europe, and 95,000 in Asia  In total, Amazon directly and indirectly supports 2 million jobs in the U S , including 680,000-plus jobs created by Amazon’s investments in areas like construction, logistics, and professional services, plus another 830,000 jobs created by small and medium-sized businesses selling on Amazon\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf\u001b[0m\n",
      "3 million MWh of energy annually—enough to power more than 580,000 U S  homes   We’ve made tremendous progress cutting packaging waste  More than a decade ago, we created the Frustration- Free Packaging program to encourage manufacturers to package their products in easy-to-open, 100% recyclable packaging that is ready to ship to customers without the need for an additional shipping box\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf\u001b[0m\n",
      " In total, Amazon directly and indirectly supports 2 million jobs in the U S , including 680,000-plus jobs created by Amazon’s investments in areas like construction, logistics, and professional services, plus another 830,000 jobs created by small and medium-sized businesses selling on Amazon  Globally, we support nearly 4 million jobs  We are especially proud of the fact that many of these are entry-level jobs that give people their first opportunity to participate in the workforce\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf\u001b[0m\n",
      " We increased our minimum wage through the end of April by $2 per hour in the U S , $2 per hour in Canada, £2 per hour in the UK, and €2 per hour in many European countries  And we are paying associates double our regular rate for any overtime worked—a minimum of $34 an hour—an increase from time and a half  These wage increases will cost more than $500 million, just through the end of April, and likely more than that over time\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf\u001b[0m\n",
      "6 times more energy efficient than the median U S  enterprise data center surveyed  Along with our use of renewable energy, these factors enable AWS to do the same tasks as traditional data centers with an 88% lower carbon footprint  And don’t think we’re not going to get those last 12 points—we’ll make AWS 100% carbon free through more investments in renewable energy projects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_answers.head().shape[0]):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\".\")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+CHUNK_SIZE]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_answers.head().shape[0]):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>S [UNK] [UNK]</td>\n",
       "      <td>119</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>5.1334352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>4.455745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>121</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>4.455745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>4.455745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf</td>\n",
       "      <td>[UNK] S</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>4.455745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                path  \\\n",
       "0  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "1  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "2  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "3  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "4  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\2019-Annual-Report-pages-1-5.pdf   \n",
       "\n",
       "          answer  chunk  start_loc  end_loc      logit   f1  \n",
       "0  S [UNK] [UNK]    119        127      129  5.1334352  0.0  \n",
       "1        [UNK] S     92        100      101   4.455745  0.0  \n",
       "2        [UNK] S    121        129      130   4.455745  0.0  \n",
       "3        [UNK] S     27         35       36   4.455745  0.0  \n",
       "4        [UNK] S    112        120      121   4.455745  0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Base Cased SQuAD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9263d1999c457fba2edbda1488e3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d333616558444b069bff1920364e3b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433294681.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6403d3d1d94315a567d3f4ffa4e962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bc7f99d5874fe88e5d7761ac4581f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a13936ac6de4cbea1c3f7fc3ae86084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=152.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-cased-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:31, 67.85s/it] \n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\".\")), CHUNK_SIZE):\n",
    "        paragraph = content.split(\".\")[i:i+CHUNK_SIZE]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\Attention in Natural Language P...</td>\n",
       "      <td>[CLS] What are the applications of Face S ##wa ##pping [SEP] org</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>2.2749405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf</td>\n",
       "      <td>[CLS] What are the applications of Face S ##wa ##pping [SEP] 2</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>-1.7819741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf</td>\n",
       "      <td>[CLS] What are the applications of Face S ##wa ##pping [SEP] 2</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>369</td>\n",
       "      <td>-1.7819741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf</td>\n",
       "      <td>[CLS] What are the applications of Face S ##wa ##pping [SEP] 2</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>334</td>\n",
       "      <td>-1.7819741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf</td>\n",
       "      <td>[CLS] What are the applications of Face S ##wa ##pping [SEP] 2</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>198</td>\n",
       "      <td>-1.7819741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  path  \\\n",
       "0  C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\Attention in Natural Language P...   \n",
       "1               C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf   \n",
       "2               C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf   \n",
       "3               C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf   \n",
       "4               C:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf   \n",
       "\n",
       "                                                             answer  chunk  \\\n",
       "0  [CLS] What are the applications of Face S ##wa ##pping [SEP] org     30   \n",
       "1    [CLS] What are the applications of Face S ##wa ##pping [SEP] 2     27   \n",
       "2    [CLS] What are the applications of Face S ##wa ##pping [SEP] 2    358   \n",
       "3    [CLS] What are the applications of Face S ##wa ##pping [SEP] 2    323   \n",
       "4    [CLS] What are the applications of Face S ##wa ##pping [SEP] 2    187   \n",
       "\n",
       "   start_loc  end_loc       logit  \n",
       "0         30       41   2.2749405  \n",
       "1         27       38  -1.7819741  \n",
       "2        358      369  -1.7819741  \n",
       "3        323      334  -1.7819741  \n",
       "4        187      198  -1.7819741  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\Attention in Natural Language Processing.pdf\u001b[0m\n",
      "the exception of pagination.  IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS  1  Attention in Natural Language Processing  Andrea Galassi  , Marco Lippi  , and Paolo Torroni  Abstract— Attention is an increasingly popular mechanism used in a wide range of neural architectures. The mechanism itself has been realized in a variety of formats. However, because of the fast-paced advances in this domain, a systematic overview of attention is still missing. In this article, we deﬁne a uniﬁed model for attention architectures in natural language processing, with a focus on those designed to work with vector representations of the textual data. We propose a\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf\u001b[0m\n",
      " Department d’Informatique et de recherché operationnelle,  Universite de Montreal, Montreal. Canada.                                                     {prashant}@iro.umontreal.ca                                    http://www-etud.iro.umontreal.ca/~prashant/        \n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf\u001b[0m\n",
      " it  an  obvious  candidate  for  fundamentally  important role in physics, like interaction, energy, momentum and other such abstractors.  This is a project report on the general attributes of Quantum Computing and Information  Processing from a layman’s point of view.    Keywords:  transformation, decoherence.                               quantum  mechanics,   computation,  EPR,   superposition,   unitary   \f",
      "      TABLE OF CONTENTS\n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf\u001b[0m\n",
      "information without physical representation”.  The fact that information is insensitive to exactly how it is expressed and can be freely  translated  from  one  form  to  another,  makes  it  an  obvious  candidate  for  fundamentally  important role in physics, like interaction, energy, momentum and other such abstractors.  This is a project report on the general attributes of Quantum Computing and Information  Processing from a layman’s point of view.    Keywords:  transformation, decoherence.                    \n",
      "\n",
      "\u001b[1mC:\\Users\\hiteshsom\\Documents\\nlp_document_finder\\Google\\research\\quantum_computing.pdf\u001b[0m\n",
      "entirely  inconceivable  situations  and  influenced  several  domains  of  modern  technologies.  There  are  many  different  ways  for  expressing  laws  of  science  in  general and laws of physics in particular. Similar to physical laws of nature, information  can  also  be  expressed  in  different  ways.  The  fact  that  information  can  be  expressed  in  different ways without losing its essential nature, leads for the possibility of the automatic  manipulation of information.    All \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_answers.head().shape[0]):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']-10: df_answers.loc[i, 'chunk']+100]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>require design and build specific</td>\n",
       "      <td>9100</td>\n",
       "      <td>9206</td>\n",
       "      <td>9210</td>\n",
       "      <td>13.2074375</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6700</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>12.380996</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>intelligence services</td>\n",
       "      <td>5300</td>\n",
       "      <td>5363</td>\n",
       "      <td>5364</td>\n",
       "      <td>8.194283</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>to have attention</td>\n",
       "      <td>10100</td>\n",
       "      <td>10200</td>\n",
       "      <td>10202</td>\n",
       "      <td>7.9642606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...</td>\n",
       "      <td>15400</td>\n",
       "      <td>15427</td>\n",
       "      <td>15464</td>\n",
       "      <td>7.942478</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                    require design and build specific   \n",
       "1                                                     to show wave nature and particle nature of light   \n",
       "2                                                                                intelligence services   \n",
       "3                                                                                    to have attention   \n",
       "4  gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit        f1  \n",
       "0   9100       9206     9210  13.2074375  0.054054  \n",
       "1   6700       6802     6810   12.380996  0.097561  \n",
       "2   5300       5363     5364    8.194283  0.000000  \n",
       "3  10100      10200    10202   7.9642606  0.000000  \n",
       "4  15400      15427    15464    7.942478  0.028571  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large uncased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:10, 92.57s/it] \n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), CHUNK_SIZE):\n",
    "        paragraph = content.split(\" \")[i:i+CHUNK_SIZE]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit  \n",
       "0   2300       2310     2315   11.70063  \n",
       "1  17500      17551    17558   11.60136  \n",
       "2   9500       9529     9533  10.294424  \n",
       "3   6050       6070     6074  10.155699  \n",
       "4   7600       7625     7659  10.107832  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "fake image detection and face video detection.  requires a large database of real and fake videos to train clas- siﬁcation models. The number of fake videos is increasingly available, but it is still limited in terms of setting a benchmark for validating various detection methods. To address this issue,\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "He is cur- rently an Associate Professor with the Department of Sciences and Methods for Engineering, Univer- sity of Modena and Reggio Emilia, Modena, Italy. His work focuses on machine learning and artiﬁ- cial intelligence, with applications to several areas, including argumentation mining, legal informatics, and medicine.  Paolo Torroni\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "(MIPR) (pp. 384-389). IEEE.  [82] Hsu, C. C., Lee, C. Y., and Zhuang, Y. X. (2018, December). Learning to detect fake face images in the wild. In 2018 International Symposium on Computer, Consumer and Control (IS3C) (pp. 388-391). IEEE. [83] Afchar, D., Nozick, V., Yamagishi, J., and Echizen, I.\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "instance, keywords can be used as a query, such as abusive speech recognition and sentiment analysis.  A different approach amounts to combining rather than comparing K and q, using them together to compute a joint representation, which is then multiplied by an importance vector3 wi mp, which has to\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "extended to accommodate multiple, possibly heterogeneous, inputs or outputs.  1) Multiple Outputs: Some applications suggest that the data could, and should, be interpreted in multiple ways. This can be the case when there is ambiguity in the data, stemming, for example, from words having multiple meanings or when addressing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+CHUNK_SIZE]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit        f1  \n",
       "0   2300       2310     2315   11.70063  0.157895  \n",
       "1  17500      17551    17558   11.60136  0.050000  \n",
       "2   9500       9529     9533  10.294424  0.108108  \n",
       "3   6050       6070     6074  10.155699  0.054054  \n",
       "4   7600       7625     7659  10.107832  0.125000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m49"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
