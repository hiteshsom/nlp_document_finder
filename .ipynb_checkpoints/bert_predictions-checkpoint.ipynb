{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Q/A Model for document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is attention mechanism\"\n",
    "# true_answer = \"The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.\"\n",
    "\n",
    "# question = \"What is quantum entanglement\"\n",
    "# true_answer = \"Quantum Entanglement allows qubits that are separated by incredible distances to interact with each other instantaneously (not limited to the speed of light).\"\n",
    "\n",
    "question = \"What are the applications of Face Swapping\"\n",
    "true_answer = \"Face swapping has a number of compelling applications in video compositing, transfiguration in portraits, and especially in  identity  protection  as  it  can  replace  faces  in  photographs by ones from a collection of stock images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large Cased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/nlp.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf',\n",
       " '/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [re.sub(r'\\n', ' ', content) for content in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:57, 74.27s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), CHUNK_SIZE):\n",
    "        paragraph = content.split(\" \")[i:i+CHUNK_SIZE]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>A [UNK] process for face manipulation detection where the [UNK] step aims to [UNK] crop and [UNK...</td>\n",
       "      <td>3100</td>\n",
       "      <td>3166</td>\n",
       "      <td>3188</td>\n",
       "      <td>7.7442517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to create a video of the target person doing or saying things</td>\n",
       "      <td>200</td>\n",
       "      <td>299</td>\n",
       "      <td>310</td>\n",
       "      <td>7.47252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6700</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>7.1532917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>applications to several [UNK] including [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo</td>\n",
       "      <td>17500</td>\n",
       "      <td>17547</td>\n",
       "      <td>17559</td>\n",
       "      <td>6.718217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>Real data [UNK] [UNK] [UNK]</td>\n",
       "      <td>6800</td>\n",
       "      <td>6900</td>\n",
       "      <td>6904</td>\n",
       "      <td>6.2739396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0  A [UNK] process for face manipulation detection where the [UNK] step aims to [UNK] crop and [UNK...   \n",
       "1                                        to create a video of the target person doing or saying things   \n",
       "2                                                     to show wave nature and particle nature of light   \n",
       "3                applications to several [UNK] including [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo   \n",
       "4                                                                          Real data [UNK] [UNK] [UNK]   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit  \n",
       "0   3100       3166     3188  7.7442517  \n",
       "1    200        299      310    7.47252  \n",
       "2   6700       6802     6810  7.1532917  \n",
       "3  17500      17547    17559   6.718217  \n",
       "4   6800       6900     6904  6.2739396  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "A recurrent convolutional model (RCN) was proposed based on the integration of the convolutional network DenseNet [68] and the gated recurrent unit cells [85] to exploit temporal discrepancies across frames (see Fig. 4). The proposed method is tested on the FaceForensics++ data set, which includes 1,000 videos [86], and shows promising results.  Fig. 4. A two-step process for face manipulation detection where the preprocessing step aims to detect, crop and align faces on a sequence of frames and the second step distinguishes manipulated and authentic face images by combining convolutional neural network (CNN) and recurrent neural network (RNN) [84].\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "to deepfake technologies. By reviewing the background of deep- fakes and state-of-the-art deepfake detection methods, this study provides a comprehensive overview of deepfake techniques and facilitates the development of new and more robust methods to deal with the increasingly challenging deepfakes.  Index Terms—survey, review, deepfakes, artiﬁcial intelligence, deep learning, computer vision, autoencoders, forensics, GAN, generative adversarial networks.  I. INTRODUCTION  Deepfake (stemming from “deep learning” and “fake”) is a technique that can superimpose face images of a target person to a video of a source person to create a video of the target person doing or saying things\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "H   Fully Silvered   Half Silvered  (Beam splitter)                                                                             Fig 3: Example to show wave nature and particle nature of light\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "He is cur- rently an Associate Professor with the Department of Sciences and Methods for Engineering, Univer- sity of Modena and Reggio Emilia, Modena, Italy. His work focuses on machine learning and artiﬁ- cial intelligence, with applications to several areas, including argumentation mining, legal informatics, and medicine.  Paolo Torroni has been an Associate Professor with the University of Bologna, Bologna, Italy, since 2015. He has edited over 20 books and special issues and authored over 150 articles in compu- tational logics, multiagent systems, argumentation, and natural language processing. His main research interest includes artiﬁcial intelligence.  Prof. Torroni \n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      " Images  8  VidTIMIT and two other original datasets obtained from the COHFACE (https://www.idiap.ch/dataset/cohface) and from YouTube. Datasets from COHFACE [127] and YouTube are used to generate two deepfake datasets by commercial website https://deepfakesweb.com and another deepfake dataset is DeepfakeTIMIT [128]. FaceForensics++ [86] and Celeb-DF (5,639 deepfake videos) [130] datasets and the ASVSpoof 2019 Logical Access audio dataset [131].  Videos  DeepfakeTIMIT [128] and DFDC [133].  The world leaders dataset [135], FaceForensics++ [86], Google/Jigsaw deepfake detection dataset [136], DFDC [133] and Celeb-DF [130].  - Real data set: CelebA-HQ [74], including high quality face images of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+CHUNK_SIZE]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>A [UNK] process for face manipulation detection where the [UNK] step aims to [UNK] crop and [UNK...</td>\n",
       "      <td>3100</td>\n",
       "      <td>3166</td>\n",
       "      <td>3188</td>\n",
       "      <td>7.7442517</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to create a video of the target person doing or saying things</td>\n",
       "      <td>200</td>\n",
       "      <td>299</td>\n",
       "      <td>310</td>\n",
       "      <td>7.47252</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6700</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>7.1532917</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>applications to several [UNK] including [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo</td>\n",
       "      <td>17500</td>\n",
       "      <td>17547</td>\n",
       "      <td>17559</td>\n",
       "      <td>6.718217</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>Real data [UNK] [UNK] [UNK]</td>\n",
       "      <td>6800</td>\n",
       "      <td>6900</td>\n",
       "      <td>6904</td>\n",
       "      <td>6.2739396</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "2                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0  A [UNK] process for face manipulation detection where the [UNK] step aims to [UNK] crop and [UNK...   \n",
       "1                                        to create a video of the target person doing or saying things   \n",
       "2                                                     to show wave nature and particle nature of light   \n",
       "3                applications to several [UNK] including [UNK] [UNK] legal [UNK] and [UNK] [UNK] Paolo   \n",
       "4                                                                          Real data [UNK] [UNK] [UNK]   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit        f1  \n",
       "0   3100       3166     3188  7.7442517  0.153846  \n",
       "1    200        299      310    7.47252  0.095238  \n",
       "2   6700       6802     6810  7.1532917  0.097561  \n",
       "3  17500      17547    17559   6.718217  0.088889  \n",
       "4   6800       6900     6904  6.2739396  0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Base Cased SQuAD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-cased-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:31, 22.90s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), CHUNK_SIZE):\n",
    "        paragraph = content.split(\" \")[i:i+CHUNK_SIZE]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>require design and build specific</td>\n",
       "      <td>9100</td>\n",
       "      <td>9206</td>\n",
       "      <td>9210</td>\n",
       "      <td>13.2074375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6700</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>12.380996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>intelligence services</td>\n",
       "      <td>5300</td>\n",
       "      <td>5363</td>\n",
       "      <td>5364</td>\n",
       "      <td>8.194283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>to have attention</td>\n",
       "      <td>10100</td>\n",
       "      <td>10200</td>\n",
       "      <td>10202</td>\n",
       "      <td>7.9642606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...</td>\n",
       "      <td>15400</td>\n",
       "      <td>15427</td>\n",
       "      <td>15464</td>\n",
       "      <td>7.942478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                    require design and build specific   \n",
       "1                                                     to show wave nature and particle nature of light   \n",
       "2                                                                                intelligence services   \n",
       "3                                                                                    to have attention   \n",
       "4  gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit  \n",
       "0   9100       9206     9210  13.2074375  \n",
       "1   6700       6802     6810   12.380996  \n",
       "2   5300       5363     5364    8.194283  \n",
       "3  10100      10200    10202   7.9642606  \n",
       "4  15400      15427    15464    7.942478  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "  description in fact contradicts some predictions of quantum mechanics.     In the face of these two perfectly convincing and contradictory results, there is only  one way out: ask Nature how it works. Till the end of 1970 there was no experimental  result to answer this question. The contradiction discovered by Bell in EPR paper, is  so  subtle  that  it  appears  only  in  a  very  peculiar  situations  that  had  not  been  investigated. And require design and build specific\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf\u001b[0m\n",
      "H   Fully Silvered   Half Silvered  (Beam splitter)                                                                             Fig 3: Example to show wave nature and particle nature of light\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "fake contents quickly. Sometimes deepfakes do not need to be spread to massive audience to cause detrimental effects. People who create deepfakes with malicious purpose only need to de- liver them to target audiences as part of their sabotage strategy without using social media. For example, this approach can be utilized by intelligence services trying to inﬂuence decisions made by important people such as politicians, leading to national and international security threats [113]. Catching the deepfake alarming problem, research community has focused on developing deepfake detection algorithms and numerous results have been reported. This paper has reviewed the state- of-the-art\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.  GALASSI et al.: ATTENTION IN NLP  13  in many scenarios, including machine translation [30], [35], visual question answering [137], and domain classiﬁcation for natural language understanding [138].  syntactical information. Chen et al. [40] and He et al. [109] used distribution functions that consider the distance between two words along the dependence graph of a sentence.  In some cases, this mechanism can also be exploited to have attention model-speciﬁc features. For example, since the linguistic information\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "2018, pp. 1815–1826.  [96] I. Lopez-Gazpio, M. Maritxalar, M. Lapata, and E. Agirre, “Word n- gram attention models for sentence similarity and inference,” Expert Syst. Appl., vol. 132, pp. 1–11, Oct. 2019. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0957417419302842  [97] E. Strubell, P. Verga, D. Andor, D. Weiss, and A. McCallum, “Linguistically-informed self-attention for semantic role labeling,” in Proc. EMNLP, 2018, pp. 5027–5038.  [98] Z. Tan, M. Wang, J. Xie, Y. Chen, and X. Shi, “Deep semantic role labeling with self-attention,” in Proc. AAAI, 2018, pp. 4929–4936. [99] T. Rocktäschel, E. Grefenstette, K. M. Hermann, T. Kociský, and P. Blunsom, “Reasoning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+CHUNK_SIZE]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>require design and build specific</td>\n",
       "      <td>9100</td>\n",
       "      <td>9206</td>\n",
       "      <td>9210</td>\n",
       "      <td>13.2074375</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf</td>\n",
       "      <td>to show wave nature and particle nature of light</td>\n",
       "      <td>6700</td>\n",
       "      <td>6802</td>\n",
       "      <td>6810</td>\n",
       "      <td>12.380996</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>intelligence services</td>\n",
       "      <td>5300</td>\n",
       "      <td>5363</td>\n",
       "      <td>5364</td>\n",
       "      <td>8.194283</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>to have attention</td>\n",
       "      <td>10100</td>\n",
       "      <td>10200</td>\n",
       "      <td>10202</td>\n",
       "      <td>7.9642606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...</td>\n",
       "      <td>15400</td>\n",
       "      <td>15427</td>\n",
       "      <td>15464</td>\n",
       "      <td>7.942478</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "1                         /home/jupyter/nlp_document_finder/Google/research/quantum_computing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                    require design and build specific   \n",
       "1                                                     to show wave nature and particle nature of light   \n",
       "2                                                                                intelligence services   \n",
       "3                                                                                    to have attention   \n",
       "4  gram attention models for sentence similarity and [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK...   \n",
       "\n",
       "   chunk  start_loc  end_loc       logit        f1  \n",
       "0   9100       9206     9210  13.2074375  0.054054  \n",
       "1   6700       6802     6810   12.380996  0.097561  \n",
       "2   5300       5363     5364    8.194283  0.000000  \n",
       "3  10100      10200    10202   7.9642606  0.000000  \n",
       "4  15400      15427    15464    7.942478  0.028571  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Large uncased SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:10, 92.57s/it] \n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\" \")), CHUNK_SIZE):\n",
    "        paragraph = content.split(\" \")[i:i+CHUNK_SIZE]\n",
    "        encoding = tokenizer.encode_plus(text=question, text_pair=paragraph)\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "        \n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "        end_index = torch.argmax(end_scores)\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        if start_index.numpy() < end_index.numpy():\n",
    "            answers.append([path, answer, i, i+start_index.numpy(), i+end_index.numpy(), (torch.max(start_scores)+torch.max(end_scores)).detach().numpy()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.DataFrame(data=answers, columns = ['path', 'answer', 'chunk', 'start_loc', 'end_loc', 'logit'])\n",
    "df_answers = df_answers.sort_values(by=['logit'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit  \n",
       "0   2300       2310     2315   11.70063  \n",
       "1  17500      17551    17558   11.60136  \n",
       "2   9500       9529     9533  10.294424  \n",
       "3   6050       6070     6074  10.155699  \n",
       "4   7600       7625     7659  10.107832  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "fake image detection and face video detection.  requires a large database of real and fake videos to train clas- siﬁcation models. The number of fake videos is increasingly available, but it is still limited in terms of setting a benchmark for validating various detection methods. To address this issue,\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "He is cur- rently an Associate Professor with the Department of Sciences and Methods for Engineering, Univer- sity of Modena and Reggio Emilia, Modena, Italy. His work focuses on machine learning and artiﬁ- cial intelligence, with applications to several areas, including argumentation mining, legal informatics, and medicine.  Paolo Torroni\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf\u001b[0m\n",
      "(MIPR) (pp. 384-389). IEEE.  [82] Hsu, C. C., Lee, C. Y., and Zhuang, Y. X. (2018, December). Learning to detect fake face images in the wild. In 2018 International Symposium on Computer, Consumer and Control (IS3C) (pp. 388-391). IEEE. [83] Afchar, D., Nozick, V., Yamagishi, J., and Echizen, I.\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "instance, keywords can be used as a query, such as abusive speech recognition and sentiment analysis.  A different approach amounts to combining rather than comparing K and q, using them together to compute a joint representation, which is then multiplied by an importance vector3 wi mp, which has to\n",
      "\n",
      "\u001b[1m/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf\u001b[0m\n",
      "extended to accommodate multiple, possibly heterogeneous, inputs or outputs.  1) Multiple Outputs: Some applications suggest that the data could, and should, be interpreted in multiple ways. This can be the case when there is ambiguity in the data, stemming, for example, from words having multiple meanings or when addressing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('\\033[1m' + df_answers.loc[i, 'path'] + '\\033[0m')\n",
    "    print(\" \".join(contents[paths.index(df_answers.loc[i, 'path'])].split(\" \")[df_answers.loc[i, 'chunk']: df_answers.loc[i, 'chunk']+CHUNK_SIZE]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_answers.loc[i, 'f1'] = compute_f1(true_answer, df_answers.loc[i, 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>logit</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>fake image detection and face video</td>\n",
       "      <td>2300</td>\n",
       "      <td>2310</td>\n",
       "      <td>2315</td>\n",
       "      <td>11.70063</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>[UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]</td>\n",
       "      <td>17500</td>\n",
       "      <td>17551</td>\n",
       "      <td>17558</td>\n",
       "      <td>11.60136</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf</td>\n",
       "      <td>to detect fake face images</td>\n",
       "      <td>9500</td>\n",
       "      <td>9529</td>\n",
       "      <td>9533</td>\n",
       "      <td>10.294424</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>abusive speech recognition and sentiment</td>\n",
       "      <td>6050</td>\n",
       "      <td>6070</td>\n",
       "      <td>6074</td>\n",
       "      <td>10.155699</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf</td>\n",
       "      <td>suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...</td>\n",
       "      <td>7600</td>\n",
       "      <td>7625</td>\n",
       "      <td>7659</td>\n",
       "      <td>10.107832</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             path  \\\n",
       "0                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "1  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "2                           /home/jupyter/nlp_document_finder/Google/research/computer_vision.pdf   \n",
       "3  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "4  /home/jupyter/nlp_document_finder/Google/research/Attention in Natural Language Processing.pdf   \n",
       "\n",
       "                                                                                                answer  \\\n",
       "0                                                                  fake image detection and face video   \n",
       "1                                                        [UNK] [UNK] legal [UNK] and [UNK] [UNK] [UNK]   \n",
       "2                                                                           to detect fake face images   \n",
       "3                                                             abusive speech recognition and sentiment   \n",
       "4  suggest that the data [UNK] and [UNK] be interpreted in multiple [UNK] [UNK] can be the case whe...   \n",
       "\n",
       "   chunk  start_loc  end_loc      logit        f1  \n",
       "0   2300       2310     2315   11.70063  0.157895  \n",
       "1  17500      17551    17558   11.60136  0.050000  \n",
       "2   9500       9529     9533  10.294424  0.108108  \n",
       "3   6050       6070     6074  10.155699  0.054054  \n",
       "4   7600       7625     7659  10.107832  0.125000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
