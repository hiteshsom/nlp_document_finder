{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPR Reader Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In Transformers v4.0.0, the default path to cache downloaded models changed from '~/.cache/torch/transformers' to '~/.cache/huggingface/transformers'. Since you don't seem to have overridden and '~/.cache/torch/transformers' is a directory that exists, we're moving it to '~/.cache/huggingface/transformers' to avoid redownloading models you have already in the cache. You should only see this message once.\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import text_utils\n",
    "import re\n",
    "from transformers import DPRReader, DPRReaderTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\probable_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = list(df['question'])\n",
    "passage_list = list(df['passage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(\n",
    "        questions=question_list,\n",
    "        texts=passage_list,\n",
    "        return_tensors='pt',\n",
    "        padding = 'max_length',\n",
    "        truncation=False,\n",
    "        max_length = 512\n",
    "    )\n",
    "\n",
    "outputs = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRReaderOutput(start_logits=tensor([[ -7.0336,  -8.3673,  -9.1825,  ..., -12.5827, -12.5468, -12.2806],\n",
       "        [ -7.0355,  -8.3648,  -9.0539,  ..., -12.3776, -12.4020, -12.3502],\n",
       "        [ -5.7824,  -7.1477,  -7.9224,  ..., -11.6871, -11.7961, -11.6917],\n",
       "        ...,\n",
       "        [-10.9493, -11.7762, -11.7722,  ..., -12.6884, -12.6545, -12.6849],\n",
       "        [ -7.6602, -10.3366, -10.0864,  ..., -12.5529, -12.5881, -12.6149],\n",
       "        [ -8.4754,  -9.5537, -10.0741,  ..., -12.7039, -12.7012, -12.6917]],\n",
       "       grad_fn=<ViewBackward>), end_logits=tensor([[ -5.4598,  -7.6801,  -8.2971,  ..., -11.6381, -11.7223, -11.8566],\n",
       "        [ -5.5072,  -7.5863,  -8.2079,  ..., -11.8185, -11.8291, -11.8891],\n",
       "        [ -4.8712,  -6.8935,  -7.5445,  ..., -10.7843, -10.7834, -10.9495],\n",
       "        ...,\n",
       "        [ -9.8667, -10.3519, -10.6474,  ..., -12.0380, -12.0677, -12.0355],\n",
       "        [ -7.7354,  -9.5509,  -9.7739,  ..., -11.9091, -11.8976, -11.8883],\n",
       "        [ -6.9224,  -7.9385,  -8.7129,  ..., -12.0161, -12.0226, -12.0227]],\n",
       "       grad_fn=<ViewBackward>), relevance_logits=tensor([ -9.5234, -10.0084, -11.4885, -12.0081,  -8.2057,  -7.4176,   9.0203,\n",
       "         -6.4598, -12.2723, -11.6577,  -7.5239,  -4.7677,  -8.6286, -11.1885,\n",
       "         -4.0777,  -5.5253,  -5.7947,  -0.9682,   0.8405,  -7.4253,  -7.1962,\n",
       "         -9.5688,  -4.4945,   2.4631,  -2.3682,  -5.5584,  -6.1421,  -5.9030,\n",
       "         -7.2256,  -5.7893,   7.0660,   0.1386,  -4.4521,  -9.7478,  -7.0957,\n",
       "         -9.1790, -10.2221,  -8.3989,  -9.0088,  -6.1838,  -4.7153,  -0.5863,\n",
       "        -10.2803,  -4.4482,  -8.9468,  -7.5856,  -7.2703,  -4.0538,   7.0267,\n",
       "         -6.9402], grad_fn=<ViewBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer not using 'titles' argument in the tokenizer\n",
      "\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "A) \n",
      "\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "A) \n",
      "\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "A) \n",
      "\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "A) \n",
      "\n",
      "which is the most common use of opt-in e-mail marketing\n",
      "A) \n",
      "\n",
      "how i.met your mother who is the mother\n",
      "A) \n",
      "\n",
      "how i.met your mother who is the mother\n",
      "A) \n",
      "\n",
      "how i.met your mother who is the mother\n",
      "A) \n",
      "\n",
      "how i.met your mother who is the mother\n",
      "A) \n",
      "\n",
      "how i.met your mother who is the mother\n",
      "A) \n",
      "\n",
      "what type of fertilisation takes place in humans\n",
      "A) \n",
      "\n",
      "what type of fertilisation takes place in humans\n",
      "A) \n",
      "\n",
      "what type of fertilisation takes place in humans\n",
      "A) \n",
      "\n",
      "what type of fertilisation takes place in humans\n",
      "A) \n",
      "\n",
      "what type of fertilisation takes place in humans\n",
      "A) \n",
      "\n",
      "who had the most wins in the nfl\n",
      "A) \n",
      "\n",
      "who had the most wins in the nfl\n",
      "A) \n",
      "\n",
      "who had the most wins in the nfl\n",
      "A) \n",
      "\n",
      "who had the most wins in the nfl\n",
      "A) \n",
      "\n",
      "who had the most wins in the nfl\n",
      "A) \n",
      "\n",
      "what happened to the lost settlement of roanoke\n",
      "A) \n",
      "\n",
      "what happened to the lost settlement of roanoke\n",
      "A) \n",
      "\n",
      "what happened to the lost settlement of roanoke\n",
      "A) \n",
      "\n",
      "what happened to the lost settlement of roanoke\n",
      "A) \n",
      "\n",
      "what happened to the lost settlement of roanoke\n",
      "A) \n",
      "\n",
      "what are the different regions of africa and how do they differ\n",
      "A) \n",
      "\n",
      "what are the different regions of africa and how do they differ\n",
      "A) \n",
      "\n",
      "what are the different regions of africa and how do they differ\n",
      "A) \n",
      "\n",
      "what are the different regions of africa and how do they differ\n",
      "A) \n",
      "\n",
      "what are the different regions of africa and how do they differ\n",
      "A) \n",
      "\n",
      "who played mantis guardians of the galaxy 2\n",
      "A) \n",
      "\n",
      "who played mantis guardians of the galaxy 2\n",
      "A) \n",
      "\n",
      "who played mantis guardians of the galaxy 2\n",
      "A) \n",
      "\n",
      "who played mantis guardians of the galaxy 2\n",
      "A) \n",
      "\n",
      "who played mantis guardians of the galaxy 2\n",
      "A) \n",
      "\n",
      "who did the voice of the magician in frosty the snowman\n",
      "A) \n",
      "\n",
      "who did the voice of the magician in frosty the snowman\n",
      "A) \n",
      "\n",
      "who did the voice of the magician in frosty the snowman\n",
      "A) \n",
      "\n",
      "who did the voice of the magician in frosty the snowman\n",
      "A) \n",
      "\n",
      "who did the voice of the magician in frosty the snowman\n",
      "A) \n",
      "\n",
      "what indian tribe did the acadians form friendships and alliances with\n",
      "A) \n",
      "\n",
      "what indian tribe did the acadians form friendships and alliances with\n",
      "A) \n",
      "\n",
      "what indian tribe did the acadians form friendships and alliances with\n",
      "A) \n",
      "\n",
      "what indian tribe did the acadians form friendships and alliances with\n",
      "A) \n",
      "\n",
      "what indian tribe did the acadians form friendships and alliances with\n",
      "A) \n",
      "\n",
      "what is considered the outer banks in north carolina\n",
      "A) \n",
      "\n",
      "what is considered the outer banks in north carolina\n",
      "A) \n",
      "\n",
      "what is considered the outer banks in north carolina\n",
      "A) \n",
      "\n",
      "what is considered the outer banks in north carolina\n",
      "A) \n",
      "\n",
      "what is considered the outer banks in north carolina\n",
      "A) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Answer not using 'titles' argument in the tokenizer\\n\")\n",
    "\n",
    "for q, p in (zip(question_list, passage_list)):\n",
    "    predicted_span = ''.join(p[np.argmax(outputs[0].detach().numpy()) : np.argmax(outputs[1].detach().numpy()) + 1])\n",
    "    print(f\"{q}\")\n",
    "    print(f\"A) {predicted_span}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpr_env",
   "language": "python",
   "name": "dpr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
