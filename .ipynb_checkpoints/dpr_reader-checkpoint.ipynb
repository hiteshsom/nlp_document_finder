{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPR Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying official example script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRReader, DPRReaderTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `titles` argument in tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(\n",
    "        questions=[\"What is love ?\"],\n",
    "        titles=[\"Haddaway\"],\n",
    "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "outputs = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage=[\"'What Is Love' is a song recorded by the artist Haddaway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer using 'titles' argument: a song\n"
     ]
    }
   ],
   "source": [
    "predicted_span = ' '.join(tokens[np.argmax(outputs[0].detach().numpy()[0]) : np.argmax(outputs[1].detach().numpy()[0]) + 1])\n",
    "print(f\"Answer using 'titles' argument: {predicted_span}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT using `titles` argument in tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(\n",
    "        questions=[\"What is love ?\"],\n",
    "#         titles=[\"Haddaway\"],\n",
    "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "outputs = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage=[\"'What Is Love' is a song recorded by the artist Haddaway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer NOT using 'titles': a song recorded by the artist had ##da ##way\n"
     ]
    }
   ],
   "source": [
    "predicted_span = ' '.join(tokens[np.argmax(outputs[0].detach().numpy()[0]) : np.argmax(outputs[1].detach().numpy()[0]) + 1])\n",
    "print(f\"Answer NOT using 'titles': {predicted_span}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying on our document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "# text = textract.process(\"C:\\\\Users\\\\hiteshsom\\\\Documents\\\\nlp_document_finder\\\\Google\\\\research\\\\2019-Annual-Report-pages-1-5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import string, re\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\hiteshsom\\\\Documents\\\\nlp_document_finder\\\\Google\\\\research\\\\2019-Annual-Report-pages-1-5.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [re.sub(r'\\n', ' ', content) for content in contents]\n",
    "contents = [ch.lower() for ch in contents]\n",
    "contents = [re.sub(r'\\x0c', ' ', content) for content in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2  0  1  9  a n n u a l  r e p o r t   to our shareowners:  one thing we’ve learned from the covid-19 crisis is how important amazon has become to our customers. we want you to know we take this responsibility seriously, and we’re proud of the work our teams are doing to help customers through this difficult time.  amazonians are working around the clock to get necessary supplies delivered directly to the doorsteps of people who need them. the demand we are seeing for essential products has been and remains high. but unlike a predictable holiday surge, this spike occurred with little warning, creating major challenges for our suppliers and delivery network. we quickly prioritized the stocking and delivery of essential household staples, medical supplies, and other critical products.  our whole foods market stores have remained open, providing fresh food and other vital goods for customers. we are taking steps to help those most vulnerable to the virus, setting aside the first hour of shopping at whole foods each day for seniors. we have temporarily closed amazon books, amazon 4-star, and amazon pop up stores because they don’t sell essential products, and we offered associates from those closed stores the opportunity to continue working in other parts of amazon.  crucially, while providing these essential services, we are focused on the safety of our employees and contractors around the world—we are deeply grateful for their heroic work and are committed to their health and well-being. consulting closely with medical experts and health authorities, we’ve made over 150 significant process changes in our operations network and whole foods market stores to help teams stay healthy, and we conduct daily audits of the measures we’ve put into place. we’ve distributed face masks and implemented temperature checks at sites around the world to help protect employees and support staff. we regularly sanitize door handles, stairway handrails, lockers, elevator buttons, and touch screens, and disinfectant wipes and hand sanitizer are standard across our network.  we’ve also introduced extensive social distancing measures to help protect our associates. we have eliminated stand-up meetings during shifts, moved information sharing to bulletin boards, staggered break times, and spread out chairs in breakrooms. while training new hires is challenging with new distancing requirements, we continue to ensure that every new employee gets six hours of safety training. we’ve shifted training protocols so we don’t have employees gathering in one spot, and we’ve adjusted our hiring processes to allow for social distancing.  a next step in protecting our employees might be regular testing of all amazonians, including those showing no symptoms. regular testing on a global scale, across all industries, would both help keep people safe and help get the economy back up and running. for this to work, we as a society would need vastly more testing capacity than is currently available. if every person could be tested regularly, it would make a huge difference in how we fight this virus. those who test positive could be quarantined and cared for, and everyone who tests negative could re-enter the economy with confidence.  we’ve begun the work of building incremental testing capacity. a team of amazonians—from research scientists and program managers to procurement specialists and software engineers—moved from their normal day jobs onto a dedicated team to work on this initiative. we have begun assembling the equipment we need to build our first lab and hope to start testing small numbers of our frontline employees soon. we are not sure how far we will get in the relevant timeframe, but we think it’s worth trying, and we stand ready to share anything we learn.   while we explore longer-term solutions, we are also committed to helping support employees now. we increased our minimum wage through the end of april by $2 per hour in the u.s., $2 per hour in canada, £2 per hour in the uk, and €2 per hour in many european countries. and we are paying associates double our regular rate for any overtime worked—a minimum of $34 an hour—an increase from time and a half. these wage increases will cost more than $500 million, just through the end of april, and likely more than that over time. while we recognize this is expensive, we believe it’s the right thing to do under the circumstances. we also established the amazon relief fund—with an initial $25 million in funding—to support our independent delivery service partners and their drivers, amazon flex participants, and temporary employees under financial distress.  in march, we opened 100,000 new positions across our fulfillment and delivery network. earlier this week, after successfully filling those roles, we announced we were creating another 75,000 jobs to respond to customer demand. these new hires are helping customers who depend on us to meet their critical needs. we know that many people around the world have suffered financially as jobs are lost or furloughed. we are happy to have them on our teams until things return to normal and either their former employer can bring them back or new jobs become available. we’ve welcomed joe duffy, who joined after losing his job as a mechanic at newark airport and learned about an opening from a friend who is an amazon operations analyst. dallas preschool teacher darby griffin joined after her school closed on march 9th and now helps manage new inventory. we’re happy to have darby with us until she can return to the classroom.  amazon is acting aggressively to protect our customers from bad actors looking to exploit the crisis. we’ve removed over half a million offers from our stores due to covid-based price gouging, and we’ve suspended more than 6,000 selling accounts globally for violating our fair-pricing policies. amazon turned over information about sellers we suspect engaged in price gouging of products related to covid-19 to 42 state attorneys general offices. to accelerate our response to price-gouging incidents, we created a special communication channel for state attorneys general to quickly and easily escalate consumer complaints to us.  amazon web services is also playing an important role in this crisis. the ability for organizations to access scalable, dependable, and highly secure computing power—whether for vital healthcare work, to help students continue learning, or to keep unprecedented numbers of employees online and productive from home—is critical in this situation. hospital networks, pharmaceutical companies, and research labs are using aws to care for patients, explore treatments, and mitigate the impacts of covid-19 in many other ways. academic institutions around the world are transitioning from in-person to virtual classrooms and are running on aws to help ensure continuity of learning. and governments are leveraging aws as a secure platform to build out new capabilities in their efforts to end this pandemic.  we are collaborating with the world health organization, supplying advanced cloud technologies and technical expertise to track the virus, understand the outbreak, and better contain its spread. who is leveraging our cloud to build large-scale data lakes, aggregate epidemiological country data, rapidly translate medical training videos into different languages, and help global healthcare workers better treat patients. we are separately making a public aws covid-19 data lake available as a centralized repository for up-to-date and curated information related to the spread and characteristics of the virus and its associated illness so experts can access and analyze the latest data in their battle against the disease.  we also launched the aws diagnostic development initiative, a program to support customers working to bring more accurate diagnostic solutions to market for covid-19. better diagnostics help accelerate treatment and containment of this pandemic. we committed $20 million to accelerate this work and help our customers harness the cloud to tackle this challenge. while the program was established in response to covid-19, we also are looking toward the future, and we will fund diagnostic research projects that have the potential to blunt future infectious disease outbreaks.   customers around the world have leveraged the cloud to scale up services and stand up responses to covid-19. we joined the new york city covid-19 rapid response coalition to develop a conversational agent to enable at-risk and elderly new yorkers to receive accurate, timely information about medical and other important needs. in response to a request from the los angeles unified school district to transition 700,000 students to remote learning, aws helped establish a call center to field it questions, provide remote support, and enable staff to answer calls. we are providing cloud services to the cdc to help thousands of public health practitioners and clinicians gather data related to covid-19 and inform response efforts. in the uk, aws provides the cloud computing infrastructure for a project that analyzes hospital occupancy levels, emergency room capacity, and patient wait times to help the country’s national health service decide where best to allocate resources. in canada, otn—one of the world’s largest virtual care networks—is scaling its aws-powered video service to accommodate a 4,000% spike in demand to support citizens as the pandemic continues. in brazil, aws will provide the são paulo state government with cloud computing infrastructure to guarantee online classes to 1 million students in public schools across the state.  following cdc guidance, our alexa health team built an experience that lets u.s. customers check their risk level for covid-19 at home. customers can ask, “alexa, what do i do if i think i have covid-19?” or “alexa, what do i do if i think i have coronavirus?” alexa then asks a series of questions about the person’s symptoms and possible exposure. based on those responses, alexa then provides cdc-sourced guidance. we created a similar service in japan, based on guidance from the japanese ministry of health, labor, and welfare.  we’re making it easy for customers to use amazon.com or alexa to donate directly to charities on the front lines of the covid-19 crisis, including feeding america, the american red cross, and save the children. echo users have the option to say, “alexa, make a donation to feeding america covid-19 response fund.” in seattle, we’ve partnered with a catering business to distribute 73,000 meals to 2,700 elderly and medically vulnerable residents in seattle and king county during the outbreak, and we donated 8,200 laptops to help seattle public schools students gain access to a device while classes are conducted virtually.  beyond covid  although these are incredibly difficult times, they are an important reminder that what we do as a company can make a big difference in people’s lives. customers count on us to be there, and we are fortunate to be able to help. with our scale and ability to innovate quickly, amazon can make a positive impact and be an organizing force for progress.  last year, we co-founded the climate pledge with christiana figueres, the un’s former climate change chief and founder of global optimism, and became the first signatory to the pledge. the pledge commits amazon to meet the goals of the paris agreement 10 years early—and be net zero carbon by 2040. amazon faces significant challenges in achieving this goal because we don’t just move information around—we have extensive physical infrastructure and deliver more than 10 billion items worldwide a year. and we believe if amazon can get to net zero carbon ten years early, any company can—and we want to work together with all companies to make it a reality.  to that end, we are recruiting other companies to sign the climate pledge. signatories agree to measure and report greenhouse gas emissions regularly, implement decarbonization strategies in line with the paris agreement, and achieve net zero annual carbon emissions by 2040. (we’ll be announcing new signatories soon.)  we plan to meet the pledge, in part, by purchasing 100,000 electric delivery vans from rivian—a michigan- based producer of electric vehicles. amazon aims to have 10,000 of rivian’s new electric vans on the road as early as 2022, and all 100,000 vehicles on the road by 2030. that’s good for the environment, but the promise is even greater. this type of investment sends a signal to the marketplace to start inventing and developing new technologies that large, global companies need to transition to a low-carbon economy.   we’ve also committed to reaching 80% renewable energy by 2024 and 100% renewable energy by 2030. (the team is actually pushing to get to 100% by 2025 and has a challenging but credible plan to pull that off.) globally, amazon has 86 solar and wind projects that have the capacity to generate over 2,300 mw and deliver more than 6.3 million mwh of energy annually—enough to power more than 580,000 u.s. homes.  we’ve made tremendous progress cutting packaging waste. more than a decade ago, we created the frustration- free packaging program to encourage manufacturers to package their products in easy-to-open, 100% recyclable packaging that is ready to ship to customers without the need for an additional shipping box. since 2008, this program has saved more than 810,000 tons of packaging material and eliminated the use of 1.4 billion shipping boxes.  we are making these significant investments to drive our carbon footprint to zero despite the fact that shopping online is already inherently more carbon efficient than going to the store. amazon’s sustainability scientists have spent more than three years developing the models, tools, and metrics to measure our carbon footprint. their detailed analysis has found that shopping online consistently generates less carbon than driving to a store, since a single delivery van trip can take approximately 100 roundtrip car journeys off the road on average. our scientists developed a model to compare the carbon intensity of ordering whole foods market groceries online versus driving to your nearest whole foods market store. the study found that, averaged across all basket sizes, online grocery deliveries generate 43% lower carbon emissions per item compared to shopping in stores. smaller basket sizes generate even greater carbon savings.  aws is also inherently more efficient than the traditional in-house data center. that’s primarily due to two things—higher utilization, and the fact that our servers and facilities are more efficient than what most companies can achieve running their own data centers. typical single-company data centers operate at roughly 18% server utilization. they need that excess capacity to handle large usage spikes. aws benefits from multi- tenant usage patterns and operates at far higher server utilization rates. in addition, aws has been successful in increasing the energy efficiency of its facilities and equipment, for instance by using more efficient evaporative cooling in certain data centers instead of traditional air conditioning. a study by 451 research found that aws’s infrastructure is 3.6 times more energy efficient than the median u.s. enterprise data center surveyed. along with our use of renewable energy, these factors enable aws to do the same tasks as traditional data centers with an 88% lower carbon footprint. and don’t think we’re not going to get those last 12 points—we’ll make aws 100% carbon free through more investments in renewable energy projects.  leveraging scale for good  over the last decade, no company has created more jobs than amazon. amazon directly employs 840,000 workers worldwide, including over 590,000 in the u.s., 115,000 in europe, and 95,000 in asia. in total, amazon directly and indirectly supports 2 million jobs in the u.s., including 680,000-plus jobs created by amazon’s investments in areas like construction, logistics, and professional services, plus another 830,000 jobs created by small and medium-sized businesses selling on amazon. globally, we support nearly 4 million jobs. we are especially proud of the fact that many of these are entry-level jobs that give people their first opportunity to participate in the workforce.  and amazon’s jobs come with an industry-leading $15 minimum wage and comprehensive benefits. more than 40 million americans—many making the federal minimum wage of $7.25 an hour—earn less than the lowest- paid amazon associate. when we raised our starting minimum wage to $15 an hour in 2018, it had an immediate and meaningful impact on the hundreds of thousands of people working in our fulfillment centers. we want other big employers to join us by raising their own minimum pay rates, and we continue to lobby for a $15 federal minimum wage.   ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DPR model to get QA prediction - not using `titles` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = [\"Beyond COVID\", \"Leveraging scale for good\"]\n",
    "# paragraphs = [\"Although these are incredibly difficult times, they are an important reminder that what we do as a company canmake a big difference in people’s lives. Customers count on us to be there, and we are fortunate to be able tohelp. With our scale and ability to innovate quickly, Amazon can make a positive impact and be an organizingforce for progress.Last year, we co-founded The Climate Pledge with Christiana Figueres, the UN’s former climate change chiefand founder of Global Optimism, and became the first signatory to the pledge. The pledge commits Amazon tomeet the goals of the Paris Agreement 10 years early—and be net zero carbon by 2040. Amazon faces significantchallenges in achieving this goal because we don’t just move information around—we have extensive physicalinfrastructure and deliver more than 10 billion items worldwide a year. And we believe if Amazon can get to netzero carbon ten years early, any company can—and we want to work together with all companies to make it areality.To that end, we are recruiting other companies to sign The Climate Pledge. Signatories agree to measure andreport greenhouse gas emissions regularly, implement decarbonization strategies in line with the ParisAgreement, and achieve net zero annual carbon emissions by 2040. (We’ll be announcing new signatories soon.)We plan to meet the pledge, in part, by purchasing 100,000 electric delivery vans from Rivian—a Michigan-based producer of electric vehicles. Amazon aims to have 10,000 of Rivian’s new electric vans on the road asearly as 2022, and all 100,000 vehicles on the road by 2030. That’s good for the environment, but the promise iseven greater. This type of investment sends a signal to the marketplace to start inventing and developing newtechnologies that large, global companies need to transition to a low-carbon economy. We’ve also committed to reaching 80% renewable energy by 2024 and 100% renewable energy by 2030. (Theteam is actually pushing to get to 100% by 2025 and has a challenging but credible plan to pull that off.)Globally, Amazon has 86 solar and wind projects that have the capacity to generate over 2,300 MW and delivermore than 6.3 million MWh of energy annually—enough to power more than 580,000 U.S. homes.We’ve made tremendous progress cutting packaging waste. More than a decade ago, we created the Frustration-Free Packaging program to encourage manufacturers to package their products in easy-to-open, 100% recyclablepackaging that is ready to ship to customers without the need for an additional shipping box. Since 2008, thisprogram has saved more than 810,000 tons of packaging material and eliminated the use of 1.4 billion shippingboxes.We are making these significant investments to drive our carbon footprint to zero despite the fact that shoppingonline is already inherently more carbon efficient than going to the store. Amazon’s sustainability scientists havespent more than three years developing the models, tools, and metrics to measure our carbon footprint. Theirdetailed analysis has found that shopping online consistently generates less carbon than driving to a store, since asingle delivery van trip can take approximately 100 roundtrip car journeys off the road on average. Our scientistsdeveloped a model to compare the carbon intensity of ordering Whole Foods Market groceries online versusdriving to your nearest Whole Foods Market store. The study found that, averaged across all basket sizes, onlinegrocery deliveries generate 43% lower carbon emissions per item compared to shopping in stores. Smaller basketsizes generate even greater carbon savings.AWS is also inherently more efficient than the traditional in-house data center. That’s primarily due to twothings—higher utilization, and the fact that our servers and facilities are more efficient than what mostcompanies can achieve running their own data centers. Typical single-company data centers operate at roughly18% server utilization. They need that excess capacity to handle large usage spikes. AWS benefits from multi-tenant usage patterns and operates at far higher server utilization rates. In addition, AWS has been successful inincreasing the energy efficiency of its facilities and equipment, for instance by using more efficient evaporativecooling in certain data centers instead of traditional air conditioning. A study by 451 Research found that AWS’sinfrastructure is 3.6 times more energy efficient than the median U.S. enterprise data center surveyed. Along withour use of renewable energy, these factors enable AWS to do the same tasks as traditional data centers with an88% lower carbon footprint. And don’t think we’re not going to get those last 12 points—we’ll make AWS 100%carbon free through more investments in renewable energy projects.\", \"Over the last decade, no company has created more jobs than Amazon. Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia. In total, Amazondirectly and indirectly supports 2 million jobs in the U.S., including 680,000-plus jobs created by Amazon’sinvestments in areas like construction, logistics, and professional services, plus another 830,000 jobs created bysmall and medium-sized businesses selling on Amazon. Globally, we support nearly 4 million jobs. We areespecially proud of the fact that many of these are entry-level jobs that give people their first opportunity toparticipate in the workforce.And Amazon’s jobs come with an industry-leading $15 minimum wage and comprehensive benefits. More than40 million Americans—many making the federal minimum wage of $7.25 an hour—earn less than the lowest-paid Amazon associate. When we raised our starting minimum wage to $15 an hour in 2018, it had an immediateand meaningful impact on the hundreds of thousands of people working in our fulfillment centers. We want otherbig employers to join us by raising their own minimum pay rates, and we continue to lobby for a $15 federalminimum wage.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many people work in Amazon ?\",\n",
    "             \"What does Whole Foods Market provide\",\n",
    "             \"When does Amazon go carbon neutral ?\",\n",
    "             \"What did Alexa team build ?\"]\n",
    "\n",
    "true_answers = [\"Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia.\",\n",
    "                \"Our Whole Foods Market stores have remained open, providing fresh food and other vital goods for customers.\",\n",
    "                \"The pledge commits Amazon tomeet the goals of the Paris Agreement 10 years early—and be net zero carbon by 2040.\",\n",
    "                \"Following CDC guidance, our Alexa health team built an experience that lets U.S. customers check their risklevel for COVID-19 at home.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK_SIZE = 5\n",
    "# q_no = 1\n",
    "# p_ans_no = 1\n",
    "# for question, true_answer in zip(questions, true_answers):\n",
    "# #     p_ans_no = 1\n",
    "# #     for w in range(0, len(contents[0].split('.')), 1):\n",
    "#     encoded_inputs = tokenizer(\n",
    "#         questions=[question]*len(contents[0].split('.')),\n",
    "#         texts=[\". \".join(contents[0].split('.')[w: w + CHUNK_SIZE]) for w in range(0, len(contents[0].split('.')), 1)],\n",
    "#         return_tensors='pt',\n",
    "#         truncation=True,\n",
    "#         padding=True\n",
    "#         )\n",
    "\n",
    "#     outputs = model(**encoded_inputs)\n",
    "    \n",
    "\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))\n",
    "\n",
    "#     predicted_span = ' '.join(tokens[np.argmax(outputs[0].detach().numpy()[0][[np.argmax(outputs[2].detach().numpy())]]) : np.argmax(outputs[1].detach().numpy()[0][[np.argmax(outputs[2].detach().numpy())]]) + 1])\n",
    "#     print(f\"\\033[1mQuestion {q_no}:\\033[0m {question}\")\n",
    "#     print(f\"\\033[1mPredicted answer :\\033[0m {predicted_span}\")\n",
    "#     print(f\"\\033[1mTrue answer:\\033[0m {true_answer}\")\n",
    "#     print(\"\\n\")\n",
    "# #     p_ans_no += 1\n",
    "#     print('\\n')\n",
    "#     q_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mQuestion 1:\u001b[0m How many people work in Amazon ?\n",
      "\u001b[1mPredicted answer 1:\u001b[0m six\n",
      "\u001b[1mTrue answer:\u001b[0m Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia.\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 1:\u001b[0m How many people work in Amazon ?\n",
      "\u001b[1mPredicted answer 2:\u001b[0m six\n",
      "\u001b[1mTrue answer:\u001b[0m Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia.\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 1:\u001b[0m How many people work in Amazon ?\n",
      "\u001b[1mPredicted answer 3:\u001b[0m six\n",
      "\u001b[1mTrue answer:\u001b[0m Amazon directly employs 840,000workers worldwide, including over 590,000 in the U.S., 115,000 in Europe, and 95,000 in Asia.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 100\n",
    "q_no = 1\n",
    "p_ans_no = 1\n",
    "for question, true_answer in zip(questions, true_answers):\n",
    "    p_ans_no = 1\n",
    "    for w in range(0, len(contents[0].split('.')), 1):\n",
    "        encoded_inputs = tokenizer(\n",
    "            questions=[question],\n",
    "        #     titles=['Annual Report'],\n",
    "            texts=[\". \".join(contents[0].split('.')[w: w + CHUNK_SIZE])],\n",
    "            return_tensors='pt',\n",
    "            max_length=512, truncation=True\n",
    "            )\n",
    "\n",
    "        outputs = model(**encoded_inputs)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))\n",
    "\n",
    "        predicted_span = ' '.join(tokens[np.argmax(outputs[0].detach().numpy()[0]) : np.argmax(outputs[1].detach().numpy()[0]) + 1])\n",
    "        print(f\"\\033[1mQuestion {q_no}:\\033[0m {question}\")\n",
    "        print(f\"\\033[1mPredicted answer {p_ans_no}:\\033[0m {predicted_span}\")\n",
    "        print(f\"\\033[1mTrue answer:\\033[0m {true_answer}\")\n",
    "        print(\"\\n\")\n",
    "        p_ans_no += 1\n",
    "    print('\\n')\n",
    "    q_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpr_env",
   "language": "python",
   "name": "dpr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
