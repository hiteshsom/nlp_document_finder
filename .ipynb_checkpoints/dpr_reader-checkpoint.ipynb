{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPR Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying example script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DPRReader were not initialized from the model checkpoint at facebook/dpr-reader-single-nq-base and are newly initialized: ['span_predictor.encoder.bert_model.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRReader, DPRReaderTokenizer\n",
    "tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "encoded_inputs = tokenizer(\n",
    "        questions=[\"What is love ?\"],\n",
    "        titles=[\"Haddaway\"],\n",
    "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "outputs = model(**encoded_inputs)\n",
    "# start_logits = outputs.start_logits\n",
    "# end_logits = outputs.end_logits\n",
    "# relevance_logits = outputs.relevance_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage=[\"'What Is Love' is a song recorded by the artist Haddaway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(list(encoded_inputs['input_ids'].numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a song\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "predicted_span = ' '.join(tokens[np.argmax(outputs[0].detach().numpy()[0]) : np.argmax(outputs[1].detach().numpy()[0]) + 1])\n",
    "print(predicted_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying on our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    path = []\n",
    "    files = []\n",
    "    for dirpath, dirname, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            if not os.path.basename(dirpath).startswith('.'):\n",
    "                path.append(dirpath)\n",
    "                files.append(f)\n",
    "            \n",
    "    return path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many position were opened in March\"\n",
    "true_answer = \"100000\"\n",
    "\n",
    "# question = \"How many new people hired by amazon\"\n",
    "# true_answer = \"100000\"\n",
    "\n",
    "# question = \"What are dominant sequence transduction models based on\"\n",
    "# true_answer = \" complex recurrent or convolutional neural networks that include an encoder and a decoder\"\n",
    "\n",
    "# question = \"What is attention mechanism\"\n",
    "# true_answer = \"The attention mechanism is a part of a neural architecture that enables to dynamically highlight relevant features of the input data, which, in NLP, is typically a sequence of textual elements. It can be applied directly to the raw input or to its higher level representation.\"\n",
    "\n",
    "# question = \"What is quantum entanglement\"\n",
    "# true_answer = \"Quantum Entanglement allows qubits that are separated by incredible distances to interact with each other instantaneously (not limited to the speed of light).\"\n",
    "\n",
    "# question = \"What are the applications of Face Swapping\"\n",
    "# true_answer = \"Face swapping has a number of compelling applications in video compositing, transfiguration in portraits, and especially in  identity  protection  as  it  can  replace  faces  in  photographs by ones from a collection of stock images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = os.getcwd()\n",
    "locations, documents = absoluteFilePaths(os.path.join(DIRECTORY, 'Google', 'research'))\n",
    "paths = [os.path.join(loc, doc) for loc, doc in zip(locations, documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\hiteshsom\\\\Documents\\\\nlp_document_finder\\\\Google\\\\research\\\\2019-Annual-Report-pages-1-5.pdf']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for path in paths:\n",
    "    if path.endswith('.pdf'):\n",
    "        contents.append(convert_pdf_to_txt(path))\n",
    "    else: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [re.sub(r'\\n', ' ', content) for content in contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using DPR model to get QA predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "There should be as many titles than texts but got 3 titles and 7 texts.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-07e689aa4021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         print(paragraph)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#         print(\"\\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m encoded_inputs = tokenizer(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mquestions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtitles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"AMAZON Reprot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Beyond Covid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Leveraging Scale for good\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\env\\lib\\site-packages\\transformers\\tokenization_dpr.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, questions, titles, texts, padding, truncation, max_length, return_tensors, return_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mn_passages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mquestions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquestions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_passages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         assert len(titles) == len(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         ), \"There should be as many titles than texts but got {} titles and {} texts.\".format(len(titles), len(texts))\n",
      "\u001b[1;31mAssertionError\u001b[0m: There should be as many titles than texts but got 3 titles and 7 texts."
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "paragraphs = []\n",
    "for path, content in tqdm(zip(paths, contents)):\n",
    "    for i in range(0, len(content.split(\".\")), CHUNK_SIZE):\n",
    "        paragraphs.append(content.split(\".\")[i:i+CHUNK_SIZE])\n",
    "#         print(paragraph)\n",
    "#         print(\"\\n\")\n",
    "encoded_inputs = tokenizer(\n",
    "    questions=[question],\n",
    "    titles=[\"AMAZON Report\", \"Beyond Covid\", \"Leveraging Scale for good\"],\n",
    "    texts=paragraphs,\n",
    "    return_tensors='pt'\n",
    "    )\n",
    "outputs = model(**encoded_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_inputs = tokenizer(\n",
    "        questions=[\"What is love ?\"],\n",
    "        titles=[\"Haddaway\"],\n",
    "        texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "outputs = model(**encoded_inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
